{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Chenyu Zhang A16526395\n",
    "- Zhengxi Zhang A17220038\n",
    "- Mengyuan Zhang A15598814\n",
    "- Harry Lei A15890785\n",
    "- Hongchang Jiang A17180573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a relationship between the severity of COVID-19 pandemic in the United States and the stock price of internationlly major automotive companies? If there is, does severity of COVID-19 have a strong positive correlation with stock price per share of automotive companies? If yes, with the severity of COVID-19 goes up, will stock price goes down. In our question, severity of COVID-19 will take into account of daily increase of death, hospitalization, positve cases and total test cases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **U.S National COVID-19 Daily Data**\n",
    "   - Dataset Name: national-history.csv\n",
    "   - Link to the dataset: https://covidtracking.com/data/download/national-history.csv\n",
    "   - Number of observations: 420 observations\n",
    "   - This dataset contain summary of daily data on the COVID-19 pandemic for the United States. It provides information on varaibles such as daily increase of death, positive cases, negative cases, hospitalization and total number of tests. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Internationlly Major Automotive Companies(Mutiple Dataset combined by 11 Individual Datasets)**\n",
    "   - Dataset Name: audi.csv,bmw.csv,gm.csv,honda.csv, gm.csv,NIO.csv, nissan.csv, rolls royces.csv, tata.csv, toyota.csv, Volkswagen.csv\n",
    "   - Link to the dataset: https://finance.yahoo.com/quote/AUDVF/history?p=AUDVF, \n",
    "                          https://finance.yahoo.com/quote/BMW.DE/history?p=BMW.DE, \n",
    "                          https://finance.yahoo.com/quote/GM/history?p=GM, \n",
    "                          https://finance.yahoo.com/quote/HMC/key-statistics?p=HMC, \n",
    "                          https://finance.yahoo.com/quote/NIO/key-statistics?p=NIO, \n",
    "                          https://finance.yahoo.com/quote/NSANY/history?p=NSANY, \n",
    "                          https://finance.yahoo.com/quote/RYCEY/history?p=RYCEY, \n",
    "                          https://finance.yahoo.com/quote/TTM/history?p=TTM, \n",
    "                          https://finance.yahoo.com/quote/TM/history?p=TM, \n",
    "                          https://finance.yahoo.com/quote/VWAGY/history?p=VWAGY\n",
    "   - Number of observations: 13312 observations\n",
    "   - This dataset contain summary of daily data on stock prices of all internationlly major automotive companies we have collected which is totally 11 dataset. It contains the variables like date, open price, high price, low price, close price, etc. The way we made this dataset is by adding a new column Maker to indicate the company for each observation, and each observation is based on the date oberserved in each individual dataset, then we performing a full join with the same column type all dataset shared since they are all come from the same source website yahoo finance.And because of that, we have the total ovservations sum of all other 11 datasets.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Audi**\n",
    "   - Dataset Name: audi.csv\n",
    "   - Link to the dataset: https://finance.yahoo.com/quote/AUDVF/history?p=AUDVF\n",
    "   - Number of observations: 1258 observations\n",
    "   - This dataset contain summary of daily data on stock prices of Audi. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "-  **Stock Price for BMW**\n",
    "    - Dataset Name: bmw.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/BMW.DE/history?p=BMW.DE\n",
    "    - Number of observations: 1267 observations\n",
    "    - This dataset contain summary of daily data on stock prices of BMW. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for General Motos**\n",
    "    - Dataset Name: gm.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/GM/history?p=GM\n",
    "    - Number of observations: 1259 observations\n",
    "    - This dataset contain summary of daily data on stock prices of General Motos. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Honda**\n",
    "    - Dataset Name: honda.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/HMC/key-statistics?p=HMC\n",
    "    - Number of observations: 1259 observations\n",
    "    - This dataset contain summary of daily data on stock prices of Honda. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for NIO**\n",
    "    - Dataset Name: NIO.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/NIO/key-statistics?p=NIO\n",
    "    - Number of observations: 743 observations\n",
    "    - This dataset contain summary of daily data on stock prices of NIO. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Nissan**\n",
    "    - Dataset Name: nissan.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/NSANY/history?p=NSANY \n",
    "    - Number of observations: 1242 observations\n",
    "    - This dataset contain summary of daily data on stock prices of Nissan. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Rolls Royce**\n",
    "    - Dataset Name: rolls royces.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/RYCEY/history?p=RYCEY \n",
    "    - Number of observations: 1265 observations\n",
    "    - This dataset contain summary of daily data on stock prices of Rolls Royce. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Tata**\n",
    "    - Dataset Name: tata.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/TTM/history?p=TTM\n",
    "    - Number of observations: 1234 observations\n",
    "    - This dataset contain summary of daily data on stock prices of Tata. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Toyota**\n",
    "    - Dataset Name: toyota.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/TM/history?p=TM \n",
    "    - Number of observations: 1259 observations\n",
    "    - This dataset contain summary of daily data on stock prices of Toyota. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Stock Price for Volkswagen**\n",
    "    - Dataset Name: Volkswagen.csv\n",
    "    - Link to the dataset: https://finance.yahoo.com/quote/VWAGY/history?p=VWAGY \n",
    "    - Number of observations: 1267 observations\n",
    "    - This dataset contain summary of daily data on stock prices of Volkswagen. It contains variables like open price, high price, low price, close price, etc. The observation for this dataset is based on the date oberserved.\n",
    "\n",
    "<br>\n",
    "\n",
    "**How to combine these datasets**: Since all datasets regarding the stock prices are from Yahoo finance, the structure for each dataframe is quite similar. Due to each stock dataframe shares a common variable, date, which represent the observation in our individual stock dataframe, thus we can just combine these datasets based on the date of individual observations. Then, consider making a new column called maker to mark the company which the observations come from, a simple concatenation would merge indivudla stock datasets into one large dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessage pacakges\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### General Steps:\n",
    "1. Concatenate dataframes of each individual automotive company into one large dataframe called **car**\n",
    "2. Add extra variable called 'Maker' to **car** dataframe to facilate further EDA analysis\n",
    "3. Drop any duplicate observations that have the same date in both **car** and **covid** dataframe\n",
    "4. Drop any columns that only has NaN values in both **car** and **covid** dataframe\n",
    "5. Filter **covid** dataframe to only include observations that has non-zero Covid cases\n",
    "6. Reduce **covid** dataframe to five variables: date, deathIncrease, hospitalizedIncrease, positiveIncrease and totalTestResultsIncrease\n",
    "7. Filter **car** dataframe to match the time scope of **covid** dataframe\n",
    "8. Rename columns of **car** dataframe to make naming conventions consistent\n",
    "9. Sort **car** dataframe in decending orders to make date consistent with **covid** dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents:\n",
    "- Stock Price Data\n",
    "  - Audi\n",
    "  - BMW\n",
    "  - General Motors\n",
    "  - Honda\n",
    "  - NIO\n",
    "  - Nissan\n",
    "  - Rolls Royces\n",
    "  - Tata\n",
    "  - Toyota\n",
    "  - Volkswagen\n",
    "- Covid-19 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Price Data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.\n",
    "First we load & clean data from the folder called 'Car', which contains csv files for each individual automotive company from 2020 to 2021. The data itself is generally clean, but we do need to mange to merge each dataframe into a large dataframe. To achieve that, we create a new variable called 'Maker', which specifies which company the observation belongs to. After the new variable is created for each observation, we concatenate each dataframe to a new dataframe by rows, thus the new dataframe contains all observations from each individual datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Maker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>699.382935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>699.382935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-26</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>699.382935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>701.549988</td>\n",
       "      <td>699.382935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>698.049988</td>\n",
       "      <td>710.000000</td>\n",
       "      <td>695.700012</td>\n",
       "      <td>695.700012</td>\n",
       "      <td>693.551025</td>\n",
       "      <td>300.0</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2016-08-24  701.549988  701.549988  701.549988  701.549988  699.382935   \n",
       "1  2016-08-25  701.549988  701.549988  701.549988  701.549988  699.382935   \n",
       "2  2016-08-26  701.549988  701.549988  701.549988  701.549988  699.382935   \n",
       "3  2016-08-29  701.549988  701.549988  701.549988  701.549988  699.382935   \n",
       "4  2016-08-30  698.049988  710.000000  695.700012  695.700012  693.551025   \n",
       "\n",
       "   Volume Maker  \n",
       "0     0.0  audi  \n",
       "1     0.0  audi  \n",
       "2     0.0  audi  \n",
       "3     0.0  audi  \n",
       "4   300.0  audi  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data from Car folder\n",
    "data_dir = 'Car'\n",
    "folder_name = ['Audi','BMW','General Motors','Honda','NIO','Nissan','Rolls Royces','Tata','Toyota','Volkswagen']\n",
    "\n",
    "file_name = []\n",
    "for name in folder_name:\n",
    "    if (name == 'NIO') or (name == 'Volkswagen'):\n",
    "        tmp = name\n",
    "    elif name == 'General Motors':\n",
    "        tmp = 'gm'\n",
    "    else:\n",
    "        tmp = name.lower()\n",
    "    file_name.append(tmp)\n",
    "\n",
    "df_name = []\n",
    "\n",
    "for i,fname in enumerate(file_name):\n",
    "    file_path = os.path.join(data_dir,folder_name[i])\n",
    "    file_path = os.path.join(file_path,fname) + '.csv'\n",
    "    if \" \" in fname:\n",
    "        fname = fname.replace(\" \",\"\")\n",
    "    globals()[fname] = pd.read_csv(file_path)\n",
    "    globals()[fname]['Maker'] = fname\n",
    "    df_name.append(fname)\n",
    "\n",
    "df_list = [audi, bmw, gm, honda, NIO, nissan, rollsroyces, tata, toyota, Volkswagen]\n",
    "car = pd.DataFrame()\n",
    "\n",
    "for df in df_list:\n",
    "    df = df.drop_duplicates(subset=['Date'])\n",
    "    car = pd.concat([car, df], axis='rows')\n",
    "\n",
    "car.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. \n",
    "For the data cleaning part, we first filtered out any duplicate observations, which are observations that share the same date, during the process of concatenation. In addition, we filtered out any columns that only have NaN values. Furthermore, given that the dataframe gathers data from 2020 to 2021, there are many observations that dates before the outbreak of Covid-19, thus we filtered out such observations to minimize any outliers that could interfere with our further analysis. Also, we renamed columns of the dataframe to make sure that the naming convention for variables can maintain consistent accross all datasets. Lastly, we sorted the dataframe by date in descending order to make date consistnt accross all datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>Volume</th>\n",
       "      <th>maker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>197.979996</td>\n",
       "      <td>198.179993</td>\n",
       "      <td>191.179993</td>\n",
       "      <td>195.740005</td>\n",
       "      <td>191.183990</td>\n",
       "      <td>1863993.0</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>331.750000</td>\n",
       "      <td>331.750000</td>\n",
       "      <td>318.799988</td>\n",
       "      <td>321.250000</td>\n",
       "      <td>321.250000</td>\n",
       "      <td>81925952.0</td>\n",
       "      <td>tata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>36.970001</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>34.900002</td>\n",
       "      <td>35.209999</td>\n",
       "      <td>35.209999</td>\n",
       "      <td>143074800.0</td>\n",
       "      <td>NIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>615.700012</td>\n",
       "      <td>591.700012</td>\n",
       "      <td>593.799988</td>\n",
       "      <td>593.799988</td>\n",
       "      <td>17810000.0</td>\n",
       "      <td>nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>54.290001</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>53.740002</td>\n",
       "      <td>54.980000</td>\n",
       "      <td>54.980000</td>\n",
       "      <td>24450500.0</td>\n",
       "      <td>gm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>626.599976</td>\n",
       "      <td>634.799988</td>\n",
       "      <td>634.799988</td>\n",
       "      <td>9564000.0</td>\n",
       "      <td>nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>4.510000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>109601300.0</td>\n",
       "      <td>NIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>27.790001</td>\n",
       "      <td>27.680000</td>\n",
       "      <td>27.780001</td>\n",
       "      <td>27.780001</td>\n",
       "      <td>320200.0</td>\n",
       "      <td>honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>181.240005</td>\n",
       "      <td>183.399994</td>\n",
       "      <td>180.679993</td>\n",
       "      <td>181.360001</td>\n",
       "      <td>170.873093</td>\n",
       "      <td>988847.0</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>892.400024</td>\n",
       "      <td>892.400024</td>\n",
       "      <td>892.400024</td>\n",
       "      <td>892.400024</td>\n",
       "      <td>892.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>audi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2859 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close    adjClose  \\\n",
       "1148  2021-03-08  197.979996  198.179993  191.179993  195.740005  191.183990   \n",
       "1120  2021-03-08  331.750000  331.750000  318.799988  321.250000  321.250000   \n",
       "624   2021-03-08   36.970001   39.480000   34.900002   35.209999   35.209999   \n",
       "1126  2021-03-08  610.000000  615.700012  591.700012  593.799988  593.799988   \n",
       "1140  2021-03-08   54.290001   56.200001   53.740002   54.980000   54.980000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "850   2020-01-17  627.000000  635.000000  626.599976  634.799988  634.799988   \n",
       "339   2020-01-17    4.510000    4.710000    4.460000    4.670000    4.670000   \n",
       "855   2020-01-17   27.760000   27.790001   27.680000   27.780001   27.780001   \n",
       "860   2020-01-17  181.240005  183.399994  180.679993  181.360001  170.873093   \n",
       "855   2020-01-17  892.400024  892.400024  892.400024  892.400024  892.400024   \n",
       "\n",
       "           Volume       maker  \n",
       "1148    1863993.0  Volkswagen  \n",
       "1120   81925952.0        tata  \n",
       "624   143074800.0         NIO  \n",
       "1126   17810000.0      nissan  \n",
       "1140   24450500.0          gm  \n",
       "...           ...         ...  \n",
       "850     9564000.0      nissan  \n",
       "339   109601300.0         NIO  \n",
       "855      320200.0       honda  \n",
       "860      988847.0  Volkswagen  \n",
       "855           0.0        audi  \n",
       "\n",
       "[2859 rows x 8 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean car dataframe\n",
    "car = car.dropna(how='all')\n",
    "car = car[ car['Date'] > '2020-01-16' ]\n",
    "car = car[ car['Date'] < '2021-03-09' ]\n",
    "car = car.rename(columns={'Date':'date','Open':'open','High':'high','Low':'low','Close':'close','Adj Close':'adjClose','Volumn':'volumn','Maker':'maker'})\n",
    "car = car.sort_values(by='date', ascending=False)\n",
    "\n",
    "car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid-19 Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.\n",
    "First we load data from the csv dataset containing national daily data on the COVID-19 pandemic of the U.S. The Data does not need to be cleaned much, given that the format for each variale is consistent. But there are many variables that have missing data. And there are many variables such as the states and onVentilatorCurrently that we will not look into for our research, which need to be cleaned to facilate our further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>death</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>negative</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>onVentilatorCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>positive</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>states</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>515151.0</td>\n",
       "      <td>842</td>\n",
       "      <td>45475.0</td>\n",
       "      <td>8134.0</td>\n",
       "      <td>726</td>\n",
       "      <td>40199.0</td>\n",
       "      <td>776361.0</td>\n",
       "      <td>74582825.0</td>\n",
       "      <td>131835</td>\n",
       "      <td>4281.0</td>\n",
       "      <td>2802.0</td>\n",
       "      <td>28756489.0</td>\n",
       "      <td>41835</td>\n",
       "      <td>56</td>\n",
       "      <td>363825123</td>\n",
       "      <td>1170059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-06</td>\n",
       "      <td>514309.0</td>\n",
       "      <td>1680</td>\n",
       "      <td>45453.0</td>\n",
       "      <td>8409.0</td>\n",
       "      <td>503</td>\n",
       "      <td>41401.0</td>\n",
       "      <td>775635.0</td>\n",
       "      <td>74450990.0</td>\n",
       "      <td>143835</td>\n",
       "      <td>4280.0</td>\n",
       "      <td>2811.0</td>\n",
       "      <td>28714654.0</td>\n",
       "      <td>60015</td>\n",
       "      <td>56</td>\n",
       "      <td>362655064</td>\n",
       "      <td>1430992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>512629.0</td>\n",
       "      <td>2221</td>\n",
       "      <td>45373.0</td>\n",
       "      <td>8634.0</td>\n",
       "      <td>2781</td>\n",
       "      <td>42541.0</td>\n",
       "      <td>775132.0</td>\n",
       "      <td>74307155.0</td>\n",
       "      <td>271917</td>\n",
       "      <td>4275.0</td>\n",
       "      <td>2889.0</td>\n",
       "      <td>28654639.0</td>\n",
       "      <td>68787</td>\n",
       "      <td>56</td>\n",
       "      <td>361224072</td>\n",
       "      <td>1744417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>510408.0</td>\n",
       "      <td>1743</td>\n",
       "      <td>45293.0</td>\n",
       "      <td>8970.0</td>\n",
       "      <td>1530</td>\n",
       "      <td>44172.0</td>\n",
       "      <td>772351.0</td>\n",
       "      <td>74035238.0</td>\n",
       "      <td>177957</td>\n",
       "      <td>4267.0</td>\n",
       "      <td>2973.0</td>\n",
       "      <td>28585852.0</td>\n",
       "      <td>65487</td>\n",
       "      <td>56</td>\n",
       "      <td>359479655</td>\n",
       "      <td>1590984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>508665.0</td>\n",
       "      <td>2449</td>\n",
       "      <td>45214.0</td>\n",
       "      <td>9359.0</td>\n",
       "      <td>2172</td>\n",
       "      <td>45462.0</td>\n",
       "      <td>770821.0</td>\n",
       "      <td>73857281.0</td>\n",
       "      <td>267001</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>3094.0</td>\n",
       "      <td>28520365.0</td>\n",
       "      <td>66836</td>\n",
       "      <td>56</td>\n",
       "      <td>357888671</td>\n",
       "      <td>1406795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     death  deathIncrease  inIcuCumulative  inIcuCurrently  \\\n",
       "0    2021-03-07  515151.0            842          45475.0          8134.0   \n",
       "1    2021-03-06  514309.0           1680          45453.0          8409.0   \n",
       "2    2021-03-05  512629.0           2221          45373.0          8634.0   \n",
       "3    2021-03-04  510408.0           1743          45293.0          8970.0   \n",
       "4    2021-03-03  508665.0           2449          45214.0          9359.0   \n",
       "..          ...       ...            ...              ...             ...   \n",
       "415  2020-01-17       NaN              0              NaN             NaN   \n",
       "416  2020-01-16       NaN              0              NaN             NaN   \n",
       "417  2020-01-15       NaN              0              NaN             NaN   \n",
       "418  2020-01-14       NaN              0              NaN             NaN   \n",
       "419  2020-01-13       NaN              0              NaN             NaN   \n",
       "\n",
       "     hospitalizedIncrease  hospitalizedCurrently  hospitalizedCumulative  \\\n",
       "0                     726                40199.0                776361.0   \n",
       "1                     503                41401.0                775635.0   \n",
       "2                    2781                42541.0                775132.0   \n",
       "3                    1530                44172.0                772351.0   \n",
       "4                    2172                45462.0                770821.0   \n",
       "..                    ...                    ...                     ...   \n",
       "415                     0                    NaN                     NaN   \n",
       "416                     0                    NaN                     NaN   \n",
       "417                     0                    NaN                     NaN   \n",
       "418                     0                    NaN                     NaN   \n",
       "419                     0                    NaN                     NaN   \n",
       "\n",
       "       negative  negativeIncrease  onVentilatorCumulative  \\\n",
       "0    74582825.0            131835                  4281.0   \n",
       "1    74450990.0            143835                  4280.0   \n",
       "2    74307155.0            271917                  4275.0   \n",
       "3    74035238.0            177957                  4267.0   \n",
       "4    73857281.0            267001                  4260.0   \n",
       "..          ...               ...                     ...   \n",
       "415         NaN                 0                     NaN   \n",
       "416         NaN                 0                     NaN   \n",
       "417         NaN                 0                     NaN   \n",
       "418         NaN                 0                     NaN   \n",
       "419         NaN                 0                     NaN   \n",
       "\n",
       "     onVentilatorCurrently    positive  positiveIncrease  states  \\\n",
       "0                   2802.0  28756489.0             41835      56   \n",
       "1                   2811.0  28714654.0             60015      56   \n",
       "2                   2889.0  28654639.0             68787      56   \n",
       "3                   2973.0  28585852.0             65487      56   \n",
       "4                   3094.0  28520365.0             66836      56   \n",
       "..                     ...         ...               ...     ...   \n",
       "415                    NaN         0.0                 0       1   \n",
       "416                    NaN         0.0                 0       1   \n",
       "417                    NaN         0.0                 0       1   \n",
       "418                    NaN         0.0                 0       1   \n",
       "419                    NaN         NaN                 0       1   \n",
       "\n",
       "     totalTestResults  totalTestResultsIncrease  \n",
       "0           363825123                   1170059  \n",
       "1           362655064                   1430992  \n",
       "2           361224072                   1744417  \n",
       "3           359479655                   1590984  \n",
       "4           357888671                   1406795  \n",
       "..                ...                       ...  \n",
       "415                 0                         0  \n",
       "416                 0                         0  \n",
       "417                 0                         0  \n",
       "418                 0                         0  \n",
       "419                 0                         0  \n",
       "\n",
       "[420 rows x 17 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read covid data from online sources\n",
    "covid = pd.read_csv('https://covidtracking.com/data/download/national-history.csv')\n",
    "covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.\n",
    "For the data cleaning part, we first filtered out any duplicate observations, which are observations that share the same date. In addition, we filtered out any columns that only have NaN values. Furthermore, we filtered out some observations that dates before the outbreak of Covid-19 to minimize outliers. Lastly, since we are focusing on daily increase of death, hospitalization, positve and test results, we filtered out any other variables that are extranuous to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>842</td>\n",
       "      <td>726</td>\n",
       "      <td>41835</td>\n",
       "      <td>1170059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-06</td>\n",
       "      <td>1680</td>\n",
       "      <td>503</td>\n",
       "      <td>60015</td>\n",
       "      <td>1430992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>2221</td>\n",
       "      <td>2781</td>\n",
       "      <td>68787</td>\n",
       "      <td>1744417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>1743</td>\n",
       "      <td>1530</td>\n",
       "      <td>65487</td>\n",
       "      <td>1590984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>2449</td>\n",
       "      <td>2172</td>\n",
       "      <td>66836</td>\n",
       "      <td>1406795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  deathIncrease  hospitalizedIncrease  positiveIncrease  \\\n",
       "0    2021-03-07            842                   726             41835   \n",
       "1    2021-03-06           1680                   503             60015   \n",
       "2    2021-03-05           2221                  2781             68787   \n",
       "3    2021-03-04           1743                  1530             65487   \n",
       "4    2021-03-03           2449                  2172             66836   \n",
       "..          ...            ...                   ...               ...   \n",
       "388  2020-02-13              0                     0                 1   \n",
       "395  2020-02-06              0                     0                 2   \n",
       "398  2020-02-03              0                     0                 1   \n",
       "411  2020-01-21              0                     0                 1   \n",
       "413  2020-01-19              0                     0                 1   \n",
       "\n",
       "     totalTestResultsIncrease  \n",
       "0                     1170059  \n",
       "1                     1430992  \n",
       "2                     1744417  \n",
       "3                     1590984  \n",
       "4                     1406795  \n",
       "..                        ...  \n",
       "388                         1  \n",
       "395                         1  \n",
       "398                         3  \n",
       "411                         0  \n",
       "413                         0  \n",
       "\n",
       "[385 rows x 5 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean covid dataframe\n",
    "covid = covid.drop_duplicates(subset=['date'])\n",
    "covid = covid.dropna(how='all')\n",
    "covid = covid[covid['positiveIncrease'] != 0.0]\n",
    "covid = covid[['date', 'deathIncrease', 'hospitalizedIncrease', 'positiveIncrease', 'totalTestResultsIncrease']]\n",
    "covid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
